# -*- coding: utf-8 -*-
"""Assignment on NEURAL NETWORK.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mWNurBgxtkdZqR2dTD8BaIDP7nGQhS2H

The dataset contains 36733 instances of 11 sensor measures aggregated over one hour (by means of average or sum) from a gas turbine. The Dataset includes gas turbine parameters (such as Turbine Inlet Temperature and Compressor Discharge pressure) in addition to the ambient variables.

Problem statement: predicting turbine energy yield (TEY) using ambient variables as features.

Attribute Information:

The explanations of sensor measurements and their brief statistics are given below.

Variable (Abbr.) Unit Min Max Mean

Ambient temperature (AT) C â€“6.23 37.10 17.71

Ambient pressure (AP) mbar 985.85 1036.56 1013.07

Ambient humidity (AH) (%) 24.08 100.20 77.87

Air filter difference pressure (AFDP) mbar 2.09 7.61 3.93

Gas turbine exhaust pressure (GTEP) mbar 17.70 40.72 25.56

Turbine inlet temperature (TIT) C 1000.85 1100.89 1081.43

Turbine after temperature (TAT) C 511.04 550.61 546.16

Compressor discharge pressure (CDP) mbar 9.85 15.16 12.06

Turbine energy yield (TEY) MWH 100.02 179.50 133.51

Carbon monoxide (CO) mg/m3 0.00 44.10 2.37

Nitrogen oxides (NOx) mg/m3 25.90 119.91 65.29
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('gas_turbines.csv')
df

y=df['TEY']
y

x=df.drop('TEY', axis = 1)
x

df.info()

df.describe().T

df.corr()

"""Feature Selection by using Mutual Information Feature Selection"""

from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest, mutual_info_regression

def select_features(x_train,y_train,x_test):
  fs = SelectKBest(score_func = mutual_info_regression, k ='all')
  fs.fit(x_train, y_train)
  x_train_fs = fs.transform(x_train)
  x_test_fs = fs.transform(x_test)
  return x_train_fs, x_test_fs,fs

x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.3, random_state = 24)
x_train_fs, x_test_fs,fs = select_features(x_train, y_train,x_test)

import matplotlib.pyplot as plt
for i in range(len(fs.scores_)):
  print('Feature %d: %f' % (i, fs.scores_[i]))
fig, ax = plt.subplots(figsize = (10,6))
plt.bar([i for i in range(len(fs.scores_))], fs.scores_)
plt.show()

"""As per above feature selection method, we will select only features with good score to build our model"""

x = df.drop(['AT','AP','AH','CO','TEY','NOX'], axis = 1)
x

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.3)

"""Artificial Neural Network Model - Backpropagation"""

from keras.models import Sequential
from keras.layers import Dense

model = Sequential()
model.add(Dense(8, input_dim = 5, activation = 'relu')) # input layer
model.add(Dense(1,activation = 'sigmoid')) # output layer

model.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics =['mse'])

history = model.fit(x, y, validation_split = 0.3, epochs = 250, batch_size = 100)

scores = model.evaluate(x,y)
print("%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

"""Hyper Parameter Tuning

PREDICT THE BURNED AREA OF FOREST FIRES WITH NEURAL NETWORKS
"""

uploaded =files.upload()

df1 = pd.read_csv('forestfires.csv')
df1

df1.shape

df1.info()

df1.describe().T

df1.corr()

from sklearn.metrics import classification_report 
from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
df1['size_category'] = label_encoder.fit_transform(df1['size_category'])

df1 = df1.drop(columns = ['month','day'], axis = 1)
df1

df1.info()

y = df1.iloc[:,-1]
y

x = df1.drop('size_category', axis=1)
x

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)

"""Artificial Neural Network Model - Backpropagation


"""

model = Sequential()
model.add(Dense(42, input_dim = 28, activation = 'relu'))
model.add(Dense(1, activation = 'sigmoid'))

model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])

history = model.fit(x_train,y_train, validation_split = 0.3, epochs = 250, batch_size= 100)

scores = model.evaluate(x,y)
print('%s: %.2f%%' % (model.metrics_names[1], scores[1]*100))

history.history.keys()

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

